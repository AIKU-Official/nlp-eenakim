{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LHoHVoAQmOG",
        "outputId": "8cdc3c38-33ba-47a9-b311-8fa1979db244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eab7-qLXq2RG",
        "outputId": "ff227877-712a-4e1e-cfb2-ed4f7aa6bbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: gluonnlp==0.8.0 in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.8.0) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "# !pip install mxnet\n",
        "!pip install gluonnlp==0.8.0\n",
        "!pip install tqdm pandas\n",
        "# !pip install sentencepiece\n",
        "#!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzQPQJgVjrw0"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import logging\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn,Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Transformer, TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# for koBART\n",
        "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hPc1Wa5Eq8TF",
        "outputId": "887975f4-f089-48a8-ee34-457db2c41db1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              lyrics\n",
              "0  날_ _이 [sep] 더_ _워_ _지_ _고 [sep] 뻐_ _근_ _해_ _진 ...\n",
              "1  달_ _래_ _러 [sep] 우_ _리 [sep] 놀_ _러 [sep] 갈_ _까_...\n",
              "2  그_ _대_ _도 [sep] 나_ _와 [sep] 같_ _은 [sep] 생_ _각_...\n",
              "3  난 [sep] 믿_ _어_ _요 [sep] 그_ _대_ _는 [sep] 어_ _떤_...\n",
              "4  생_ _각_ _해_ _보_ _니 [sep] 너_ _무_ _도 [sep] 바_ _쁘_..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29619854-6c89-4be9-8e77-de0766eb48eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>날_ _이 [sep] 더_ _워_ _지_ _고 [sep] 뻐_ _근_ _해_ _진 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>달_ _래_ _러 [sep] 우_ _리 [sep] 놀_ _러 [sep] 갈_ _까_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>그_ _대_ _도 [sep] 나_ _와 [sep] 같_ _은 [sep] 생_ _각_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>난 [sep] 믿_ _어_ _요 [sep] 그_ _대_ _는 [sep] 어_ _떤_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>생_ _각_ _해_ _보_ _니 [sep] 너_ _무_ _도 [sep] 바_ _쁘_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29619854-6c89-4be9-8e77-de0766eb48eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29619854-6c89-4be9-8e77-de0766eb48eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29619854-6c89-4be9-8e77-de0766eb48eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b86c527-b602-412c-b374-8de8a6449f24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b86c527-b602-412c-b374-8de8a6449f24')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b86c527-b602-412c-b374-8de8a6449f24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# train dataset\n",
        "#train = pd.read_csv('train_lyrics.csv', names=['lyrics', 'syllables'])\n",
        "train = pd.read_csv(\n",
        "    \"final_syl.csv\", sep=\"\\t\", header=None, names=[\"lyrics\"], encoding=\"utf-8-sig\"\n",
        ")\n",
        "train = train[:len(train) // 2]\n",
        "\n",
        "# 데이터프레임을 출력하여 확인합니다.\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train.iloc[10000, 0]\n",
        "print(re.sub('_ _', '', x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxUfP0jV2R30",
        "outputId": "091f1c83-edf4-4f0a-af45-a16b9d4b640d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신이 [sep] 맞다면 [sep]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_KBjGsGf_zw",
        "outputId": "b2d7fa5d-2884-4098-e2e4-4e4066d5dcee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>나는 나는 갯바위 당신은 나를 사랑하는 파도 어느 고운 바람 불던날 잔잔히 다가와 부드러운 손길로 나를 감싸고 향기로운 입술도 내게 주었지 세찬 비바람에 내몸이 패이고 이는 파도에 깨끗이 부서져도 나의 생은 당신의 조각품인것을 나는 당신으로 인해 아름다운 것을 나는 나는 갯바위 당신은 나를 사랑하는 파도 우린 오늘도 마주보며 이렇게 서있네 세찬 비바람에 내몸이 패이고 이는 파도에 깨끗이 부서져도 나의 생은 당신의 조각품인것을 나는 당신으로 인해 아름다운 것을 나는 나는 갯바위 당신은 나를 사랑하는 파도 우린 오늘도 마주보며 이렇게 서있네 나는 나는 갯바위 당신은 나를 사랑하는 파도 우린 오늘도 마주보며 이렇게 서있네 이렇게 서있네 </s>\n"
          ]
        }
      ],
      "source": [
        "x = train.iloc[1, 0]\n",
        "print(\"<s>\" + re.sub('\\[sep\\]', '', re.sub(' \\[sep\\] ', ' ', x)) + \"</s>\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train.iloc[1, 1]\n",
        "print(\"<s>\" + re.sub('([0-9])', '<unused\\\\1>', re.sub(' ', '', re.sub('\\[sep\\]', '', x))) + \"</s>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybSy8EupJyNt",
        "outputId": "0fa82637-b214-4705-d52a-09f71227a0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s><unused2><unused2><unused3><unused3><unused2><unused4><unused2><unused2><unused2><unused2><unused3><unused3><unused3><unused4><unused3><unused2><unused3><unused4><unused3><unused2><unused3><unused2><unused4><unused3><unused3><unused2><unused3><unused3><unused4><unused2><unused2><unused3><unused6><unused2><unused4><unused2><unused4><unused2><unused2><unused2><unused3><unused3><unused2><unused4><unused2><unused2><unused3><unused4><unused3><unused3><unused2><unused4><unused3><unused3><unused2><unused3><unused3><unused4><unused2><unused2><unused3><unused6><unused2><unused4><unused2><unused4><unused2><unused2><unused2><unused3><unused3><unused2><unused4><unused2><unused2><unused3><unused4><unused3><unused3><unused2><unused2><unused3><unused3><unused2><unused4><unused2><unused2><unused3><unused4><unused3><unused3><unused3><unused3></s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zwi9baAlW5eZ",
        "outputId": "ff39753f-0de7-42b7-d0ff-2d7ac22521c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'난<unused0>오늘도<unused0>조용히<unused0>그댈<unused0>그리워하네'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.sub(' \\[sep\\] ', '<unused0>', \"난 [sep] 오늘도 [sep] 조용히 [sep] 그댈 [sep] 그리워하네\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REnCTKMuLaHv"
      },
      "outputs": [],
      "source": [
        "def make_decoder_input(x, eos_token=1, pad_token=3):\n",
        "  # Use torch.roll to shi\n",
        "  # shift the elements to the right by one place\n",
        "  x = torch.roll(x, shifts=1, dims=1)\n",
        "\n",
        "  # Set the first column to </s>\n",
        "  x[:, 0] = eos_token\n",
        "\n",
        "  # Check where the value is '3'\n",
        "  matches = (x == pad_token)\n",
        "\n",
        "  # Use torch.where to get the indices\n",
        "  indices = [torch.where(m)[0][0] if m.sum() > 0 else 0 for m in matches]\n",
        "\n",
        "  for i, index in enumerate(indices):\n",
        "    x[i, index - 1] = pad_token\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0py4h-GxgYbX"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "# gc.collect()\n",
        "# del model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['lyrics'].apply(lambda x: re.sub('_ _', '', x))\n",
        "type(y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MURiUbjoE-A9",
        "outputId": "189f29ae-19c5-4604-bc72-5ae1c85aad14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FMB_h10Geh8"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, file, tokenizer, max_length=256):\n",
        "        self.inputs = []\n",
        "        lyrics_list = file['lyrics'].apply(lambda x: re.sub('_ _', '', x))\n",
        "        for lyric in lyrics_list:\n",
        "          notes = [f\"<unused{len(word)}>\" if word != \"[sep]\" else '<unused0>' for word in lyric.split()]\n",
        "          self.inputs.append(\"<s>\" + ' '.join(notes) + \"</s>\") # 더 나은 코드가 있을텐데..\n",
        "        self.outputs = list(lyrics_list.apply(lambda x: \"<s>\" + re.sub('\\[sep\\]', '<unused0>', x) + \"</s>\"))\n",
        "        # self.inputs = list(file['syllables'].apply(lambda x: \"<s>\" + re.sub('([0-9])', '<unused\\\\1>', re.sub(' ', '', re.sub('\\[sep\\]', '', x))) + \"</s>\")\n",
        "        # self.outputs = list(file['lyrics'].apply(lambda x: \"<s>\" + re.sub('\\[sep\\]', '', re.sub(' \\[sep\\] ', ' ', x)) + \"</s>\")\n",
        "        self.tokenizer = tokenizer\n",
        "        # self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        print(self.inputs[0])\n",
        "        print(self.outputs[0])\n",
        "\n",
        "        input_tokens = self.tokenizer(self.inputs, padding=\"max_length\", max_length=max_length, truncation=True, return_tensors='pt')\n",
        "        output_tokens = self.tokenizer(self.outputs, padding=\"max_length\", max_length=max_length, truncation=True, return_tensors='pt')\n",
        "\n",
        "        self.input_ids = input_tokens['input_ids']\n",
        "        self.labels = output_tokens['input_ids']\n",
        "        self.decoder_input_ids = make_decoder_input(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.decoder_input_ids[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB02VmJJGUu6"
      },
      "outputs": [],
      "source": [
        "class KoBARTConditionalGeneration(nn.Module):\n",
        "    def __init__(self, device = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        super().__init__()\n",
        "        self.model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-base-v1').to(device)\n",
        "        self.model.train()\n",
        "        self.bos_token = '<s>'\n",
        "        self.eos_token = '</s>'\n",
        "        self.sep_token = '<unused0>'\n",
        "        self.device = device\n",
        "\n",
        "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')\n",
        "        self.pad_token_id = self.tokenizer.pad_token_id\n",
        "\n",
        "    def forward(self, input_ids, decoder_input_ids, labels):\n",
        "        attention_mask = input_ids.ne(self.pad_token_id).float().to(self.device) #input_ids.ne()안을 올바르게 채워주세요\n",
        "        decoder_attention_mask = decoder_input_ids.ne(self.pad_token_id).float().to(self.device) #decoder_input_ids.ne()안을 올바르게 채워주세요\n",
        "\n",
        "        return self.model(input_ids=input_ids.to(self.device),\n",
        "                          attention_mask=attention_mask,\n",
        "                          decoder_input_ids=decoder_input_ids.to(self.device),\n",
        "                          decoder_attention_mask=decoder_attention_mask,\n",
        "                          labels=labels, return_dict=True)\n",
        "\n",
        "    def generate(self, *args, **kwargs):\n",
        "      return self.model.generate(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZfWsaC1OD_f"
      },
      "outputs": [],
      "source": [
        "def dataset_split(dataset, ratio):\n",
        "    train_size = int(ratio * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "    return train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_fFPOVIOP9m",
        "outputId": "6fc35b31-26e0-4f62-bb9f-0b47fdde99a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        }
      ],
      "source": [
        "model = KoBARTConditionalGeneration()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfPJlJTgOKEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6a1307-d9ab-429b-85bd-61799edb4467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s><unused2> <unused0> <unused4> <unused0> <unused4> <unused0> <unused2> <unused0></s>\n",
            "<s>날이 <unused0> 더워지고 <unused0> 뻐근해진 <unused0> 몸을 <unused0></s>\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32 # 자신의 현재 GPU 성능에 맞게 조절해 주세요.\n",
        "\n",
        "dataset = MyDataset(train, model.tokenizer)\n",
        "train_dataset, val_dataset = dataset_split(dataset, 0.8)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWTuVcH_PZyl"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger()  ###진행 과정에서 로깅 포인트가 발생할 경우 로깅을 하기 위한 코드입니다. 수정하실 필요 없습니다\n",
        "logger.setLevel(logging.INFO)  ###진행 과정에서 로깅 포인트가 발생할 경우 로깅을 하기 위한 코드입니다. 수정하실 필요 없습니다\n",
        "\n",
        "# Config\n",
        "epochs = 10\n",
        "warmup_ratio = 0.1\n",
        "learning_rate = 3e-5\n",
        "grad_clip = 1.0\n",
        "# train_log_interval = 100 ##train이 100번 이루어질 때마다 logging되도록 한 코드입니다\n",
        "# validation_interval = 1000 ##1000번의 train이 끝날 때마다 validation을 수행\n",
        "save_interval = 1000 ##save point는 1000번의 train\n",
        "\n",
        "# optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(\n",
        "        nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(\n",
        "        nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=False)\n",
        "\n",
        "# scheduler\n",
        "data_len = len(train_dataloader)\n",
        "num_train_steps = int(data_len / batch_size * epochs)\n",
        "#num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
        "#scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj5k_0X0PecF",
        "outputId": "2b26dd7d-c8db-4af1-efff-aa5564ede030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:data length 18063\n",
            "INFO:root:num_train_steps : 5644\n"
          ]
        }
      ],
      "source": [
        "# logging data info : logging 정보를 지정된 로깅 포인트마다 제시해 주도록 하는 코드입니다.\n",
        "logging.info(f'data length {data_len}')\n",
        "logging.info(f'num_train_steps : {num_train_steps}')\n",
        "#logging.info(f'num_warmup_steps : {num_warmup_steps}')\n",
        "\n",
        "\n",
        "#하드웨어 가속기에 따라 device 값을 설정해주는 코드입니다. 따로 수정하실 필요 없습니다!\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def _validate( #학습 시 검증을 위한 것입니다.\n",
        "        model: KoBARTConditionalGeneration,\n",
        "        dev_dataloader: DataLoader,\n",
        "        device: torch.device,\n",
        "        logger: logging.Logger,\n",
        "        global_step: int,\n",
        "):\n",
        "    model.eval()  # 모델을 평가 모드로 전환합니다.\n",
        "    loss_list = []\n",
        "    for batch_data in tqdm(dev_dataloader, desc=\"[EVAL]\"):\n",
        "        with torch.no_grad():\n",
        "            input_ids, decoder_input_ids, labels = batch_data\n",
        "            model_outputs = model.forward(input_ids, decoder_input_ids, labels)\n",
        "            loss_list.append(model_outputs.loss.item())\n",
        "\n",
        "    mean_loss = np.mean(loss_list)\n",
        "    logger.info(f\"[EVAL] global_step:{global_step} loss:{mean_loss:.4f} perplexity:{math.exp(mean_loss):.4f}\")\n",
        "    model.train()\n",
        "\n",
        "    return mean_loss\n",
        "\n",
        "def bart_train(model, optimizer, train_dataloader, val_dataloader, device):\n",
        "    model.to(device)  # 모델 학습을 설정된 device (CPU, cuda) 위에서 진행하도록 하는 코드입니다.\n",
        "    model.train() # 모델을 학습 모드로 전환합니다.\n",
        "    loss_list_between_log_interval = []\n",
        "    for epoch_id in range(epochs):\n",
        "        for step_index, batch_data in tqdm(enumerate(train_dataloader), f\"[TRAIN] Epoch:{epoch_id+1}\", total=len(train_dataloader)):\n",
        "                global_step = len(train_dataloader) * epoch_id + step_index + 1\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                input_ids, decoder_input_ids, labels = batch_data\n",
        "                #print(input_ids)\n",
        "\n",
        "                model_outputs = model(input_ids, decoder_input_ids, labels)\n",
        "\n",
        "                loss = model_outputs.loss\n",
        "                loss.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                optimizer.step()\n",
        "                #scheduler.step()\n",
        "\n",
        "                # for logging\n",
        "                loss_list_between_log_interval.append(model_outputs.loss.item())\n",
        "\n",
        "                #if global_step % train_log_interval == 0:\n",
        "        mean_loss = np.mean(loss_list_between_log_interval)\n",
        "        logger.info(\n",
        "            f\"EP:{epoch_id} global_step:{global_step} \"\n",
        "            f\"loss:{mean_loss:.4f} perplexity:{math.exp(mean_loss):.4f}\"\n",
        "        )\n",
        "        loss_list_between_log_interval.clear()\n",
        "\n",
        "                # if global_step % validation_interval == 0:\n",
        "        dev_loss = _validate(model, val_dataloader, device, logger, global_step)\n",
        "\n",
        "        #print(\"saving model...\")\n",
        "        state_dict = model.state_dict()\n",
        "        model_path = os.path.join('/content/drive/MyDrive/ML/my_AIKU/AIKU_project/Kim_yina/kobart', f\"epoch_{epoch_id}.pth\")\n",
        "        logger.info(f\"global_step: {global_step} model saved at {model_path}\")\n",
        "        torch.save(state_dict, model_path)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK_JbeMJRFwv"
      },
      "outputs": [],
      "source": [
        "model = bart_train(model, optimizer, train_dataloader, val_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KoBARTConditionalGeneration()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ML/my_AIKU/AIKU_project/Kim_yina/kobart/epoch_3.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "uCDebx5a9Eto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EezXu_kBRakR"
      },
      "outputs": [],
      "source": [
        "def syllables2lyrics(model, notes):\n",
        "  notes = [f\"<unused{n}> <unused0>\" for n in notes]\n",
        "  input_text = \"<s> + \" \" \".join(notes) + </s>\n",
        "  input_ids = model.tokenizer.encode(input_text, add_special_tokens=True, return_tensors=\"pt\").to('cuda')\n",
        "  generated_ids = model.generate(input_ids, max_length=50, num_beams=4)\n",
        "  generated_text = model.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "  print(\"Generated Text:\", generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}